<?xml version="1.0" encoding="UTF-8"?>
<!-- Dernière modification
     le       $Date$
     par      $Author$
     révision $Revision$ -->

 <chapter id="performance-tips">
  <title>Conseils sur les performances</title>

  <indexterm zone="performance-tips">
    <primary>performance</primary>
  </indexterm>

  <para>
   La performance des requêtes peut être affectée par un grand nombre d'éléments.
   Certains peuvent être contrôlés par l'utilisateur, d'autres sont
   fondamentaux au concept sous-jacent du système. Ce chapitre fournit des
   conseils sur la compréhension et sur la configuration fine des performances
   de <productname>PostgreSQL</productname>.
  </para>

  <sect1 id="using-explain">
   <title>Utiliser <command>EXPLAIN</command></title>

   <indexterm zone="using-explain">
    <primary>EXPLAIN</primary>
   </indexterm>

   <indexterm zone="using-explain">
    <primary>plan de requête</primary>
   </indexterm>

   <para>
    <productname>PostgreSQL</productname> réalise un <firstterm>plan
    de requête</firstterm> pour chaque requête qu'il reçoit. Choisir le bon
    plan correspondant à la structure de la requête et aux propriétés des
    données est absolument critique pour de bonnes performances, donc le système
    inclut un <firstterm>planificateur</firstterm> complexe qui tente de choisir
    les bons plans. Vous pouvez
    utiliser la commande <xref linkend="sql-explain"/>
    pour voir quel plan de requête le planificateur crée pour une requête particulière.
    Plan-reading is an art that requires some experience to master,
    but this section attempts to cover the basics.
   </para>
 
   <para>
    Examples in this section are drawn from the regression test database
    after doing a <command>VACUUM ANALYZE</command>, using 9.2 development sources.
    You should be able to get similar results if you try the examples
    yourself, but your estimated costs and row counts might vary slightly
    because <command>ANALYZE</command>'s statistics are random samples rather
    than exact, and because costs are inherently somewhat platform-dependent.
   </para>

   <para>
    The examples use <command>EXPLAIN</command>'s default <quote>text</quote> output
    format, which is compact and convenient for humans to read.
    If you want to feed <command>EXPLAIN</command>'s output to a program for further
    analysis, you should use one of its machine-readable output formats
    (XML, JSON, or YAML) instead.
   </para>

  <sect2 id="using-explain-basics">
   <title><command>EXPLAIN</command> Basics</title>

   <para>
    La structure d'un plan de requête est un arbre de <firstterm>n&oelig;uds
    de plan</firstterm>. Les n&oelig;uds de bas niveau sont les n&oelig;uds
    de parcours&nbsp;: ils renvoient les lignes brutes d'une table. Il existe
    différents types de n&oelig;uds de parcours pour les différentes méthodes
    d'accès aux tables&nbsp;: parcours séquentiel, parcours d'index et parcours
    d'index bitmap. There are also non-table row sources, such as <literal>VALUES</literal>
    clauses and set-returning functions in <literal>FROM</literal>, which have their
    own scan node types.
    Si la requête requiert des jointures, agrégations, tris
    ou d'autres opérations sur les lignes brites, ce seront des n&oelig;uds
    supplémentaires au-dessus des n&oelig;uds de parcours pour réaliser ces
    opérations. Encore une fois, il existe plus d'une façon de réaliser ces
    opérations, donc différents types de n&oelig;uds peuvent aussi apparaître
    ici.  La sortie
    d'<command>EXPLAIN</command> comprend une ligne pour chaque n&oelig;ud dans
    l'arbre du plan, montrant le type de n&oelig;ud basique avec les estimations
    de coût que le planificateur a fait pour l'exécution de ce n&oelig;ud du
    plan. Additional lines might appear,
    indented from the node's summary line,
    to show additional properties of the node.
    La première ligne (the summary line for the topmost
    node) comprend le coût
    d'exécution total estimé pour le plan&nbsp;; c'est ce nombre que le
    planificateur cherche à minimiser.
   </para>

   <para>
    Voici un exemple trivial, juste pour montrer à quoi ressemble l'affichage.

<screen>EXPLAIN SELECT * FROM tenk1;

                         QUERY PLAN
-------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..458.00 rows=10000 width=244)</screen>
   </para>

   <para>
    Since this query has no <literal>WHERE</literal> clause, it must scan all the
    rows of the table, so the planner has chosen to use a simple sequential
    scan plan.  The numbers that are quoted in parentheses are (left
     to right):

    <itemizedlist>
     <listitem>
      <para>
       Coût estimé du lancement. This is the time expended before the output
       phase can begin, e.g., time to do the sorting in a sort node.&nbsp;;
      </para>
     </listitem>

     <listitem>
      <para>
       Coût total estimé.  This is stated on the assumption that the plan
       node is run to completion, i.e., all available rows are retrieved.
       In practice a node's parent node might stop short of reading all
       available rows (see the <literal>LIMIT</literal> example below).
      </para>
     </listitem>

     <listitem>
      <para>
       Nombre de lignes estimé en sortie par ce n&oelig;ud de plan.  Again, the node
       is assumed to be run to completion.
      </para>
     </listitem>

     <listitem>
      <para>
       Largeur moyenne estimée (en octets) des lignes en sortie par ce
       n&oelig;ud de plan.
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <para>
    Les coûts sont mesurés en unités arbitraires déterminées par les paramètres
    de coût du planificateur (voir <xref linkend="runtime-config-query-constants"/>).
    La pratique habituelle est de mesurer les coûts en unité de récupération de
    pages disque&nbsp;; autrement dit, <xref linkend="guc-seq-page-cost"/> est
    initialisé à <literal>1.0</literal> par convention et les autres paramètres
    de coût sont relatifs à cette valeur. Les exemples de cette section sont
    exécutés avec les paramètres de coût par défaut.
   </para>

   <para>
    Il est important de comprendre que le coût d'un n&oelig;ud de haut niveau inclut
    le coût de tous les n&oelig;uds fils. Il est aussi important de réaliser
    que le coût reflète seulement les éléments d'importance pour le
    planificateur. En particulier, le coût ne considère pas le temps
    dépensé dans la transmission des lignes de résultat au client, ce qui
    pourrait être un facteur important dans le temps réel passé&nbsp;; mais
    le planificateur l'ignore parce qu'il ne peut pas le changer en modifiant
    le plan (chaque plan correct sortira le même ensemble de lignes).
   </para>

   <para>
    La valeur <literal>rows</literal> est un peu difficile car il ne s'agit
    pas du nombre de lignes traitées ou parcourues par le
    plan de n&oelig;uds, but rather the number emitted by the node.This is often
    less than the number scanned, as a result of filtering by any
    <literal>WHERE</literal>-clause conditions that are being applied at the node.
    Ideally the top-level rows estimate will approximate the number of rows
    actually returned, updated, or deleted by the query.
   </para>

   <para>
    Pour revenir à notre exemple&nbsp;:

<screen>EXPLAIN SELECT * FROM tenk1;

                         QUERY PLAN
-------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..458.00 rows=10000 width=244)</screen>
   </para>

   <para>
    These numbers are derived very straightforwardly. Si vous faîtes&nbsp;:

<screen>SELECT relpages, reltuples FROM pg_class WHERE relname = 'tenk1';</screen>

    vous trouverez que <classname>tenk1</classname> a 358 pages disque et 10000
    lignes. Le coût estimé est calculé avec (nombre de pages lues *
    <xref linkend="guc-seq-page-cost"/>) + (lignes parcourues *
    <xref linkend="guc-cpu-tuple-cost"/>).  Par défaut,
    <varname>seq_page_cost</varname> vaut 1.0 et <varname>cpu_tuple_cost</varname>
    vaut 0.01. Donc le coût estimé est de (358 * 1.0) + (10000 * 0.01),
    soit 458.
   </para>

   <para>
    Maintenant, modifions la requête originale pour ajouter une condition
    <literal>WHERE</literal>&nbsp;:

<screen>EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 7000;

                         QUERY PLAN
------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..483.00 rows=7001 width=244)
   Filter: (unique1 &lt; 7000)</screen>

    Notez que l'affichage d'<command>EXPLAIN</command> montre la clause <literal>WHERE</literal>
    appliquée comme une condition de <quote>filtre</quote> attached to the Seq
    Scan plan node&nbsp;; ceci signifie que le
    n&oelig;ud de plan vérifie la condition pour chaque ligne qu'il parcourt et
    ne conserve que celles qui satisfont la condition.
    L'estimation des lignes en sortie a baissé à cause de la clause
    <literal>WHERE</literal>. Néanmoins, le parcours devra toujours visiter les 10000
    lignes, donc le coût n'a pas baissé&nbsp;; en fait, il a un peu augmenté
    (par 10000 * <xref linkend="guc-cpu-operator-cost"/> pour être exact)
    dans le but de refléter le temps CPU supplémentaire dépensé pour vérifier
    la condition <literal>WHERE</literal>.
   </para>

   <para>
    Le nombre réel de lignes que cette requête sélectionnera est 7000 mais
    l'estimation <literal>rows</literal> est approximative. Si vous tentez
    de dupliquer cette
    expérience, vous obtiendrez probablement une estimation légèrement
    différente&nbsp;; de plus, elle changera après chaque commande
    <command>ANALYZE</command> parce que les statistiques produites par
    <command>ANALYZE</command> sont prises à partir d'un extrait au hasard de la
    table.
   </para>

   <para>
    Maintenant, rendons la condition plus restrictive&nbsp;:

<screen>EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100;

                                  QUERY PLAN
------------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=5.03..229.17 rows=101 width=244)
   Recheck Cond: (unique1 &lt; 100)
   ->  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.01 rows=101 width=0)
         Index Cond: (unique1 &lt; 100)</screen>

    Ici, le planificateur a décidé d'utiliser un plan en deux étapes&nbsp;: le
    n&oelig;ud en bas du plan visite un index pour trouver l'emplacement des
    lignes correspondant à la condition de l'index, puis le n&oelig;ud du plan
    du dessus récupère réellement ces lignes de la table. Récupérer séparément
    les lignes est bien plus coûteux que de les lire séquentiellement mais
    comme toutes les pages de la table n'ont pas à être visitées, cela revient
    toujours moins cher qu'un parcours séquentiel (la raison de l'utilisation
    d'un plan à deux niveaux est que le n&oelig;ud du plan du dessus trie les
    emplacements des lignes identifiés par l'index dans l'ordre physique avant
    de les lire pour minimiser les coûts des récupérations séparés. Le
    <quote>bitmap</quote> mentionné dans les noms de n&oelig;uds est le mécanisme
    qui s'occupe du tri).
   </para>

   <para>
    Now let's add another condition to the <literal>WHERE</literal> clause:

<screen>EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND stringu1 = 'xxx';

                                  QUERY PLAN
------------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=5.01..229.40 rows=1 width=244)
   Recheck Cond: (unique1 &lt; 100)
   Filter: (stringu1 = 'xxx'::name)
   -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.01 rows=101 width=0)
         Index Cond: (unique1 &lt; 100)
</screen>
 
    The added condition <literal>stringu1 = 'xxx'</literal> reduces the
    output-rowcount estimate, but not the cost because we still have to visit
    the same set of rows.  Notice that the <literal>stringu1</literal> clause
    cannot be applied as an index condition, since this index is only on
    the <literal>unique1</literal> column.  Instead it is applied as a filter on
    the rows retrieved by the index.  Thus the cost has actually gone up
    slightly to reflect this extra checking.
   </para>

   <para>
    In some cases the planner will prefer a <quote>simple</quote> index scan plan:

<screen>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 = 42;
 
                                 QUERY PLAN
-----------------------------------------------------------------------------
 Index Scan using tenk1_unique1 on tenk1  (cost=0.00..8.27 rows=1 width=244)
   Index Cond: (unique1 = 42)
</screen>
 
    In this type of plan the table rows are fetched in index order, which
    makes them even more expensive to read, but there are so few that the
    extra cost of sorting the row locations is not worth it.  You'll most
    often see this plan type for queries that fetch just a single row.  It's
    also often used for queries that have an <literal>ORDER BY</literal> condition
    that matches the index order, because then no extra sort step is needed to
    satisfy the <literal>ORDER BY</literal>.
    </para>
 
    <para>
    If there are indexes on several columns referenced in <literal>WHERE</literal>,
    the planner might choose to use an AND or OR combination of the indexes:
 
<screen>
 EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000;
 
                                      QUERY PLAN
 -------------------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=25.01..60.14 rows=10 width=244)
    Recheck Cond: ((unique1 &lt; 100) AND (unique2 &gt; 9000))
   -&gt;  BitmapAnd  (cost=25.01..25.01 rows=10 width=0)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.01 rows=101 width=0)
                Index Cond: (unique1 &lt; 100)
         -&gt;  Bitmap Index Scan on tenk1_unique2  (cost=0.00..19.74 rows=999 width=0)
                Index Cond: (unique2 &gt; 9000)
</screen>
    Mais ceci requiert de visiter plusieurs index, donc ce n'est pas nécessaire
    un gain comparé à l'utilisation d'un seul index et au traitement de l'autre
    condition par un filtre. Si vous variez les échelles de valeurs impliquées,
    vous vous apercevrez que le plan change en accord.
   </para>

   <para>
    Here is an example showing the effects of <literal>LIMIT</literal>:

<screen>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000 LIMIT 2;

                                     QUERY PLAN
-------------------------------------------------------------------------------------
 Limit  (cost=0.00..14.25 rows=2 width=244)
   -&gt;  Index Scan using tenk1_unique2 on tenk1  (cost=0.00..71.23 rows=10 width=244)
         Index Cond: (unique2 &gt; 9000)
         Filter: (unique1 &lt; 100)
</screen>
   </para>

   <para>
    This is the same query as above, but we added a <literal>LIMIT</literal> so that
    not all the rows need be retrieved, and the planner changed its mind about
    what to do.  Notice that the total cost and row count of the Index Scan
    node are shown as if it were run to completion.  However, the Limit node
    is expected to stop after retrieving only a fifth of those rows, so its
    total cost is only a fifth as much, and that's the actual estimated cost
    of the query.  This plan is preferred over adding a Limit node to the
    previous plan because the Limit could not avoid paying the startup cost
    of the bitmap scan, so the total cost would be something over 25 units
    with that approach.
   </para>

   <para>
    Maintenant, essayons de joindre deux tables, en utilisant les colonnes dont
    nous avons discuté&nbsp;:

<screen>
 EXPLAIN SELECT *
 FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t1.unique2 = t2.unique2;
 
                                       QUERY PLAN
 --------------------------------------------------------------------------------------
 Nested Loop  (cost=4.33..118.25 rows=10 width=488)
   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=4.33..39.44 rows=10 width=244)
         Recheck Cond: (unique1 &lt; 10)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..4.33 rows=10 width=0)
               Index Cond: (unique1 &lt; 10)
   -&gt;  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.00..7.87 rows=1 width=244)
          Index Cond: (unique2 = t1.unique2)
</screen>
    </para>
 
    <para>
    In this plan, we have a nested-loop join node with two table scans as
    inputs, or children.  The indentation of the node summary lines reflects
    the plan tree structure.  The join's first, or <quote>outer</quote>, child
    is a bitmap scan similar to those we saw before.  Its cost and row count
    are the same as we'd get from <literal>SELECT ... WHERE unique1 &lt; 10</literal>
    because we are
    applying the <literal>WHERE</literal> clause <literal>unique1 &lt; 10</literal>
     at that node.
     The <literal>t1.unique2 = t2.unique2</literal> clause is not relevant yet,
    so it doesn't affect the row count of the outer scan.  The nested-loop
    join node will run its second,
    or <quote>inner</quote> child once for each row obtained from the outer child.
    Column values from the current outer row can be plugged into the inner
    scan; here, the <literal>t1.unique2</literal> value from the outer row is available,
    so we get a plan and costs similar to what we saw above for a simple
    <literal>SELECT ... WHERE t2.unique2 = <replaceable>constant</replaceable></literal> case.
    (The estimated cost is actually a bit lower than what was seen above,
    as a result of caching that's expected to occur during the repeated
    indexscans on <literal>t2</literal>.)  The
     costs of the loop node are then set on the basis of the cost of the outer
    scan, plus one repetition of the inner scan for each outer row (10 * 7.87,
     here), plus a little CPU time for join processing.
    </para>

   <para>
    Dans cet exemple, le nombre de lignes en sortie de la jointure est
    identique aux nombres de lignes des deux parcours mais ce n'est pas vrai
    en règle générale car vous pouvez avoir des clauses <literal>WHERE</literal>
    mentionnant les deux tables et qui, donc, peuvent seulement être appliquées au
    point de jointure, et non pas aux parcours d'index.
    For example, if we add one more condition:

<screen>
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t1.unique2 = t2.unique2 AND t1.hundred &lt; t2.hundred;

                                      QUERY PLAN
--------------------------------------------------------------------------------------
 Nested Loop  (cost=4.33..118.28 rows=3 width=488)
   Join Filter: (t1.hundred &lt; t2.hundred)
   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=4.33..39.44 rows=10 width=244)
         Recheck Cond: (unique1 &lt; 10)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..4.33 rows=10 width=0)
               Index Cond: (unique1 &lt; 10)
   -&gt;  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.00..7.87 rows=1 width=244)
         Index Cond: (unique2 = t1.unique2)
</screen>

    The extra condition <literal>t1.hundred &lt; t2.hundred</literal> can't be
    tested in the <literal>tenk2_unique2</literal> index, so it's applied at the
    join node.  This reduces the estimated output row count of the join node,
    but does not change either input scan.
   </para>

   <para>
    When dealing with outer joins, you might see join plan nodes with both
    <quote>Join Filter</quote> and plain <quote>Filter</quote> conditions attached.
    Join Filter conditions come from the outer join's <literal>ON</literal> clause,
    so a row that fails the Join Filter condition could still get emitted as
    a null-extended row.  But a plain Filter condition is applied after the
    outer-join rules and so acts to remove rows unconditionally.  In an inner
    join there is no semantic difference between these types of filters.
   </para>

   <para>
    If we change the query's selectivity a bit, we might get a very different
    join plan:

<screen>
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;

                                        QUERY PLAN
------------------------------------------------------------------------------------------
 Hash Join  (cost=230.43..713.94 rows=101 width=488)
   Hash Cond: (t2.unique2 = t1.unique2)
   -&gt;  Seq Scan on tenk2 t2  (cost=0.00..445.00 rows=10000 width=244)
   -&gt;  Hash  (cost=229.17..229.17 rows=101 width=244)
         -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=5.03..229.17 rows=101 width=244)
               Recheck Cond: (unique1 &lt; 100)
               -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.01 rows=101 width=0)
                     Index Cond: (unique1 &lt; 100)
</screen>
   </para>

   <para>
    Here, the planner has chosen to use a hash join, in which rows of one
    table are entered into an in-memory hash table, after which the other
    table is scanned and the hash table is probed for matches to each row.
    Again note how the indentation reflects the plan structure: the bitmap
    scan on <literal>tenk1</literal> is the input to the Hash node, which constructs
    the hash table.  That's then returned to the Hash Join node, which reads
    rows from its outer child plan and searches the hash table for each one.
   </para>

   <para>
    Another possible type of join is a merge join, illustrated here:

<screen>
EXPLAIN SELECT *
FROM tenk1 t1, onek t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;

                                        QUERY PLAN
------------------------------------------------------------------------------------------
 Merge Join  (cost=197.83..267.93 rows=10 width=488)
   Merge Cond: (t1.unique2 = t2.unique2)
   -&gt;  Index Scan using tenk1_unique2 on tenk1 t1  (cost=0.00..656.25 rows=101 width=244)
         Filter: (unique1 &lt; 100)
   -&gt;  Sort  (cost=197.83..200.33 rows=1000 width=244)
         Sort Key: t2.unique2
         -&gt;  Seq Scan on onek t2  (cost=0.00..148.00 rows=1000 width=244)
</screen>
   </para>

   <para>
    Merge join requires its input data to be sorted on the join keys.  In this
    plan the <literal>tenk1</literal> data is sorted by using an index scan to visit
    the rows in the correct order, but a sequential scan and sort is preferred
    for <literal>onek</literal>, because there are many more rows to be visited in
    that table.
    (Seqscan-and-sort frequently beats an indexscan for sorting many rows,
    because of the nonsequential disk access required by the indexscan.)
   </para>

   <para>
    Une façon de rechercher des plans différents est de forcer le planificateur
    à oublier certaines stratégies qu'il aurait trouvé moins coûteuses en
    utilisant les
    options d'activation (enable)/désactivation (disable) décrites dans la <xref
    linkend="runtime-config-query-enable"/> (c'est un outil complexe mais utile&nbsp;;
    voir aussi la <xref linkend="explicit-joins"/>).
    For example, if we're unconvinced that seqscan-and-sort is the best way to
    deal with table <literal>onek</literal> in the previous example, we could try

<screen>
SET enable_sort = off;
EXPLAIN SELECT *
FROM tenk1 t1, onek t2
 WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;
 
                                         QUERY PLAN
 ------------------------------------------------------------------------------------------
 Merge Join  (cost=0.00..292.36 rows=10 width=488)
   Merge Cond: (t1.unique2 = t2.unique2)
   -&gt;  Index Scan using tenk1_unique2 on tenk1 t1  (cost=0.00..656.25 rows=101 width=244)
         Filter: (unique1 &lt; 100)
   -&gt;  Index Scan using onek_unique2 on onek t2  (cost=0.00..224.76 rows=1000 width=244)
</screen>
 
    which shows that the planner thinks that sorting <literal>onek</literal> by
    indexscanning is about 12% more expensive than seqscan-and-sort.
    Of course, the next question is whether it's right about that.
    We can investigate that using <command>EXPLAIN ANALYZE</command>, as discussed
    below.
    </para>
 
  </sect2>

  <sect2 id="using-explain-analyze">
   <title><command>EXPLAIN ANALYZE</command></title>

    <para>
    It is possible to check the accuracy of the planner's estimates
    by using <command>EXPLAIN</command>'s <literal>ANALYZE</literal> option.  With this
    option, <command>EXPLAIN</command> actually executes the query, and then displays
    the true row counts and true run time accumulated within each plan node,
    along with the same estimates that a plain <command>EXPLAIN</command>
    shows.  For example, we might get a result like this:
 
 <screen>
 EXPLAIN ANALYZE SELECT *
 FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t1.unique2 = t2.unique2;

                                                           QUERY PLAN
---------------------------------------------------------------------------------------------------------------------------------
 Nested Loop  (cost=4.33..118.25 rows=10 width=488) (actual time=0.370..1.126 rows=10 loops=1)
   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=4.33..39.44 rows=10 width=244) (actual time=0.254..0.380 rows=10 loops=1)
         Recheck Cond: (unique1 &lt; 10)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..4.33 rows=10 width=0) (actual time=0.164..0.164 rows=10 loops=1)
               Index Cond: (unique1 &lt; 10)
   -&gt;  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.00..7.87 rows=1 width=244) (actual time=0.041..0.048 rows=1 loops=10)
          Index Cond: (unique2 = t1.unique2)
 Total runtime: 2.414 ms</screen>

    Notez que les valeurs <quote>temps réel</quote> sont en millisecondes alors
    que les estimations de <quote>coût</quote> sont exprimées dans des unités
    arbitraires&nbsp;; donc il y a peu de chances qu'elles correspondent.
    The thing that's usually most important to look for is whether the
    estimated row counts are reasonably close to reality.  In this example
    the estimates were all dead-on, but that's quite unusual in practice.
   </para>

   <para>
    Dans certains plans de requête, il est possible qu'un n&oelig;ud de
    sous-plan soit exécuté plus d'une fois. Par exemple, le parcours d'index
    interne est exécuté une fois par ligne externe dans le plan de boucle
    imbriquée ci-dessus. Dans de tels cas, la valeur <literal>loops</literal>
    renvoie le nombre total d'exécution du n&oelig;ud, et le temps réel et les
    valeurs des lignes affichées sont une moyenne par exécution. Ceci est fait
    pour que les nombres soient comparables avec la façon dont les estimations
    de coûts sont affichées. Multipliez par la valeur de <literal>loops</literal>
    pour obtenir le temps total réellement passé dans le n&oelig;ud.  In the above example, we spent a total of 0.480 milliseconds
    executing the indexscans on <literal>tenk2</literal>.
   </para>

   <para>
    In some cases <command>EXPLAIN ANALYZE</command> shows additional execution
    statistics beyond the plan node execution times and row counts.
    For example, Sort and Hash nodes provide extra information:

<screen>
EXPLAIN ANALYZE SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2 ORDER BY t1.fivethous;

                                                                 QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------------------------
 Sort  (cost=717.30..717.56 rows=101 width=488) (actual time=104.950..105.327 rows=100 loops=1)
   Sort Key: t1.fivethous
   Sort Method: quicksort  Memory: 68kB
   -&gt;  Hash Join  (cost=230.43..713.94 rows=101 width=488) (actual time=3.680..102.396 rows=100 loops=1)
         Hash Cond: (t2.unique2 = t1.unique2)
         -&gt;  Seq Scan on tenk2 t2  (cost=0.00..445.00 rows=10000 width=244) (actual time=0.046..46.219 rows=10000 loops=1)
         -&gt;  Hash  (cost=229.17..229.17 rows=101 width=244) (actual time=3.184..3.184 rows=100 loops=1)
               Buckets: 1024  Batches: 1  Memory Usage: 27kB
               -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=5.03..229.17 rows=101 width=244) (actual time=0.612..1.959 rows=100 loops=1)
                     Recheck Cond: (unique1 &lt; 100)
                     -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.01 rows=101 width=0) (actual time=0.390..0.390 rows=100 loops=1)
                           Index Cond: (unique1 &lt; 100)
 Total runtime: 107.392 ms
</screen>

    The Sort node shows the sort method used (in particular, whether the sort
    was in-memory or on-disk) and the amount of memory or disk space needed.
    The Hash node shows the number of hash buckets and batches as well as the
    peak amount of memory used for the hash table.  (If the number of batches
    exceeds one, there will also be disk space usage involved, but that is not
    shown.)
   </para>

   <para>
    Another type of extra information is the number of rows removed by a
    filter condition:

<screen>
EXPLAIN ANALYZE SELECT * FROM tenk1 WHERE ten &lt; 7;

                                                QUERY PLAN
----------------------------------------------------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..483.00 rows=7000 width=244) (actual time=0.111..59.249 rows=7000 loops=1)
   Filter: (ten &lt; 7)
   Rows Removed by Filter: 3000
 Total runtime: 85.340 ms
</screen>

    These counts can be particularly valuable for filter conditions applied at
    join nodes.  The <quote>Rows Removed</quote> line only appears when at least
    one scanned row, or potential join pair in the case of a join node,
    is rejected by the filter condition.
   </para>

   <para>
    A case similar to filter conditions occurs with <quote>lossy</quote>
    indexscans.  For example, consider this search for polygons containing a
    specific point:

<screen>
EXPLAIN ANALYZE SELECT * FROM polygon_tbl WHERE f1 @&gt; polygon '(0.5,2.0)';

                                              QUERY PLAN
------------------------------------------------------------------------------------------------------
 Seq Scan on polygon_tbl  (cost=0.00..1.05 rows=1 width=32) (actual time=0.251..0.251 rows=0 loops=1)
   Filter: (f1 @&gt; '((0.5,2))'::polygon)
   Rows Removed by Filter: 4
 Total runtime: 0.517 ms
</screen>

    The planner thinks (quite correctly) that this sample table is too small
    to bother with an indexscan, so we have a plain sequential scan in which
    all the rows got rejected by the filter condition.  But if we force an
    indexscan to be used, we see:

<screen>
SET enable_seqscan TO off;

EXPLAIN ANALYZE SELECT * FROM polygon_tbl WHERE f1 @&gt; polygon '(0.5,2.0)';

                                                        QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------
 Index Scan using gpolygonind on polygon_tbl  (cost=0.00..8.27 rows=1 width=32) (actual time=0.293..0.293 rows=0 loops=1)
   Index Cond: (f1 @&gt; '((0.5,2))'::polygon)
   Rows Removed by Index Recheck: 1
 Total runtime: 1.054 ms
</screen>

    Here we can see that the index returned one candidate row, which was
    then rejected by a recheck of the index condition.  This happens because a
    GiST index is <quote>lossy</quote> for polygon containment tests: it actually
    returns the rows with polygons that overlap the target, and then we have
    to do the exact containment test on those rows.
   </para>

   <para>
    <command>EXPLAIN</command> has a <literal>BUFFERS</literal> option that can be used with
    <literal>ANALYZE</literal> to get even more runtime statistics:

<screen>
EXPLAIN (ANALYZE, BUFFERS) SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000;

                                                            QUERY PLAN
-----------------------------------------------------------------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=25.07..60.23 rows=10 width=244) (actual time=3.069..3.213 rows=10 loops=1)
   Recheck Cond: ((unique1 &lt; 100) AND (unique2 &gt; 9000))
   Buffers: shared hit=16
   -&gt;  BitmapAnd  (cost=25.07..25.07 rows=10 width=0) (actual time=2.967..2.967 rows=0 loops=1)
         Buffers: shared hit=7
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.02 rows=102 width=0) (actual time=0.732..0.732 rows=200 loops=1)
               Index Cond: (unique1 &lt; 100)
               Buffers: shared hit=2
         -&gt;  Bitmap Index Scan on tenk1_unique2  (cost=0.00..19.80 rows=1007 width=0) (actual time=2.015..2.015 rows=1009 loops=1)
               Index Cond: (unique2 &gt; 9000)
               Buffers: shared hit=5
 Total runtime: 3.917 ms
</screen>

    The numbers provided by <literal>BUFFERS</literal> help to identify which parts
    of the query are the most I/O-intensive.
   </para>

   <para>
    Keep in mind that because <command>EXPLAIN ANALYZE</command> actually
    runs the query, any side-effects will happen as usual, even though
    whatever results the query might output are discarded in favor of
    printing the <command>EXPLAIN</command> data.  If you want to analyze a
    data-modifying query without changing your tables, you can
    roll the command back afterwards, for example:

<screen>
BEGIN;

EXPLAIN ANALYZE UPDATE tenk1 SET hundred = hundred + 1 WHERE unique1 &lt; 100;

                                                           QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------------
 Update on tenk1  (cost=5.03..229.42 rows=101 width=250) (actual time=81.055..81.055 rows=0 loops=1)
   -&gt;  Bitmap Heap Scan on tenk1  (cost=5.03..229.42 rows=101 width=250) (actual time=0.766..3.396 rows=100 loops=1)
         Recheck Cond: (unique1 &lt; 100)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.01 rows=101 width=0) (actual time=0.461..0.461 rows=100 loops=1)
               Index Cond: (unique1 &lt; 100)
 Total runtime: 81.922 ms

ROLLBACK;
</screen>
   </para>

   <para>
    As seen in this example, when the query is an <command>INSERT</command>,
    <command>UPDATE</command>, or <command>DELETE</command> command, the actual work of
    applying the table changes is done by a top-level Insert, Update,
    or Delete plan node.  The plan nodes underneath this node perform
    the work of locating the old rows and/or computing the new data.
    So above, we see the same sort of bitmap table scan we've seen already,
    and its output is fed to an Update node that stores the updated rows.
    It's worth noting that although the data-modifying node can take a
    considerable amount of runtime (here, it's consuming the lion's share
    of the time), the planner does not currently add anything to the cost
    estimates to account for that work.  That's because the work to be done is
    the same for every correct query plan, so it doesn't affect planning
    decisions.
   </para>

   <para>
     The <literal>Total runtime</literal> shown by <command>EXPLAIN
    ANALYZE</command> includes executor start-up and shut-down time, as well
    as the time to run any triggers that are fired, but it does not include
    parsing, rewriting, or planning time.
    Time spent executing <literal>BEFORE</literal> triggers, if any, is included in
    the time for the related Insert, Update, or Delete node; but time
    spent executing <literal>AFTER</literal> triggers is not counted there because
    <literal>AFTER</literal> triggers are fired after completion of the whole plan.
    The total time spent in each trigger
    (either <literal>BEFORE</literal> or <literal>AFTER</literal>) is also shown separately.
    Note that deferred constraint triggers will not be executed
    until end of transaction and are thus not shown at all by
     <command>EXPLAIN ANALYZE</command>.
    </para>
 
  </sect2>

  <sect2 id="using-explain-caveats">
   <title>Caveats</title>

   <para>
    Il existe deux raisons importantes pour lesquelles les temps d'exécution
    mesurés par <command>EXPLAIN ANALYZE</command> peuvent dévier de l'exécution
    normale de la même requête. Tout d'abord, comme aucune ligne n'est
    réellement envoyée au client, les coûts de conversion réseau et les coûts
    de formatage des entrées/sorties ne sont pas inclus.
    Second, the measurement overhead added by <command>EXPLAIN
    ANALYZE</command> can be significant, especially on machines with slow
    <function>gettimeofday()</function> operating-system calls. You can use the
    <xref linkend="pgtesttiming"/> tool to measure the overhead of timing
    on your system.
   </para>

   <para>
    Les résultats de <command>EXPLAIN</command> ne devraient
    pas être extrapolés pour des situations autres que celles de vos tests en
    cours&nbsp;; par exemple, les résultats sur une petite table ne peuvent
    être appliqués à des tables bien plus importantes. Les estimations de coût
    du planificateur ne sont pas linéaires et, du coup, il pourrait bien
    choisir un plan différent pour une table plus petite ou plus grande. Un
    exemple extrême est celui d'une table occupant une page disque. Vous
    obtiendrez pratiquement toujours un parcours séquentiel que des index soient
    disponibles ou non. Le planificateur réalise que cela va nécessiter la
    lecture d'une seule page disque pour traiter la table dans ce cas, il n'y a
    donc pas d'intérêt à étendre des lectures de pages supplémentaires pour un
    index. (We saw this happening in the
    <literal>polygon_tbl</literal> example above.)
   </para>

   <para>
    There are cases in which the actual and estimated values won't match up
    well, but nothing is really wrong.  One such case occurs when
    plan node execution is stopped short by a <literal>LIMIT</literal> or similar
    effect.  For example, in the <literal>LIMIT</literal> query we used before,

<screen>
EXPLAIN ANALYZE SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000 LIMIT 2;

                                                          QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.00..14.25 rows=2 width=244) (actual time=1.652..2.293 rows=2 loops=1)
   -&gt;  Index Scan using tenk1_unique2 on tenk1  (cost=0.00..71.23 rows=10 width=244) (actual time=1.631..2.259 rows=2 loops=1)
         Index Cond: (unique2 &gt; 9000)
         Filter: (unique1 &lt; 100)
         Rows Removed by Filter: 287
 Total runtime: 2.857 ms
</screen>

    the estimated cost and rowcount for the Index Scan node are shown as
    though it were run to completion.  But in reality the Limit node stopped
    requesting rows after it got two, so the actual rowcount is only 2 and
    the runtime is less than the cost estimate would suggest.  This is not
    an estimation error, only a discrepancy in the way the estimates and true
    values are displayed.
   </para>

   <para>
    Merge joins also have measurement artifacts that can confuse the unwary.
    A merge join will stop reading one input if it's exhausted the other input
    and the next key value in the one input is greater than the last key value
    of the other input; in such a case there can be no more matches and so no
    need to scan the rest of the first input.  This results in not reading all
    of one child, with results like those mentioned for <literal>LIMIT</literal>.
    Also, if the outer (first) child contains rows with duplicate key values,
    the inner (second) child is backed up and rescanned for the portion of its
    rows matching that key value.  <command>EXPLAIN ANALYZE</command> counts these
    repeated emissions of the same inner rows as if they were real additional
    rows.  When there are many outer duplicates, the reported actual rowcount
    for the inner child plan node can be significantly larger than the number
    of rows that are actually in the inner relation.
   </para>

   <para>
    BitmapAnd and BitmapOr nodes always report their actual rowcounts as zero,
    due to implementation limitations.
   </para>
  </sect2>

 </sect1>

 <sect1 id="planner-stats">
  <title>Statistiques utilisées par le planificateur</title>

  <indexterm zone="planner-stats">
   <primary>statistiques</primary>
   <secondary>du planificateur</secondary>
  </indexterm>

  <para>
   Comme nous avons vu dans la section précédente, le planificateur de requêtes
   a besoin d'estimer le nombre de lignes récupérées par une requête pour faire
   les bons choix dans ses plans de requêtes. Cette section fournit un aperçu
   rapide sur les statistiques que le système utilise pour ces estimations.
  </para>

  <para>
   Un élément des statistiques est le nombre total d'entrées dans chaque
   table et index, ainsi que le nombre de blocs disque occupés par chaque table
   et index. Cette information est conservée dans la table
   <link linkend="catalog-pg-class"><structname>pg_class</structname></link>
   sur les colonnes <structfield>reltuples</structfield> et
   <structfield>relpages</structfield>. Nous pouvons la regarder avec des
   requêtes comme celle-ci&nbsp;:

<screen>SELECT relname, relkind, reltuples, relpages
FROM pg_class
WHERE relname LIKE 'tenk1%';

       relname        | relkind | reltuples | relpages
----------------------+---------+-----------+----------
 tenk1                | r       |     10000 |      358
 tenk1_hundred        | i       |     10000 |       30
 tenk1_thous_tenthous | i       |     10000 |       30
 tenk1_unique1        | i       |     10000 |       30
 tenk1_unique2        | i       |     10000 |       30
(5 rows)</screen>

   Ici, nous pouvons voir que <structname>tenk1</structname> contient 10000
   lignes, comme pour ses index, mais que les index sont bien plus petits que la
   table (ce qui n'est pas surprenant).
  </para>

  <para>
   Pour des raisons d'efficacité, <structfield>reltuples</structfield> et
   <structfield>relpages</structfield> ne sont pas mis à jour en temps réel, et
   du coup, elles contiennent habituellement des valeurs un peu obsolètes. Elles
   sont mises à jour par les commandes <command>VACUUM</command>, <command>ANALYZE</command>
   et quelques commandes DDL comme <command>CREATE INDEX</command>. 
   A <command>VACUUM</command>
   or <command>ANALYZE</command> operation that does not scan the entire table
   (which is commonly the case) will incrementally update the
   <structfield>reltuples</structfield> count on the basis of the part
   of the table it did scan, resulting in an approximate value.
   Dans tous les cas, le planificateur mettra à l'échelle
   les valeurs qu'il aura trouver dans <structname>pg_class</structname> pour
   correspondre à la taille physique de la table, obtenant ainsi une
   approximation plus proche de la réalité.
  </para>

  <indexterm>
   <primary>pg_statistic</primary>
  </indexterm>

  <para>
   La plupart des requêtes ne récupère qu'une fraction des lignes dans une
   table à cause de clauses <literal>WHERE</literal> qui restreignent les lignes à
   examiner. Du coup, le planificateur a besoin d'une estimation de la
   <firstterm>sélectivité</firstterm> des clauses <literal>WHERE</literal>, c'est-à-dire la
   fraction des lignes qui correspondent à chaque condition de la clause
   <literal>WHERE</literal>. L'information utilisée pour cette tâche est stockée dans
   le catalogue système <link
   linkend="catalog-pg-statistic"><structname>pg_statistic</structname></link>.
   Les entrées de <structname>pg_statistic</structname> sont mises à jour par
   les commandes <command>ANALYZE</command> et <command>VACUUM ANALYZE</command> et sont
   toujours approximatives même si elles ont été mises à jour récemment.
  </para>

  <indexterm>
   <primary>pg_stats</primary>
  </indexterm>

  <para>
   Plutôt que de regarder directement dans
   <structname>pg_statistic</structname>, il est mieux de visualiser sa vue
   <link linkend="view-pg-stats"><structname>pg_stats</structname></link>
   lors de l'examen manuel des statistiques.
   <structname>pg_stats</structname> est conçu pour être plus facilement
   lisible. De plus, <structname>pg_stats</structname> est lisible par tous
   alors que <structname>pg_statistic</structname> n'est lisible que par un
   superutilisateur (ceci empêche les utilisateurs non privilégiés d'apprendre
   certains choses sur le contenu des tables appartenant à d'autres personnes à
   partir des statistiques. La vue <structname>pg_stats</structname> est restreinte
   pour afficher seulement les lignes des tables lisibles par l'utilisateur courant).
   Par exemple, nous pourrions lancer&nbsp;:

<screen>SELECT attname, inherited, n_distinct,
       array_to_string(most_common_vals, E'\n') as most_common_vals
FROM pg_stats
WHERE tablename = 'road';

 attname | inherited | n_distinct |          most_common_vals          
---------+-----------+------------+------------------------------------
 name    | f         |  -0.363388 | I- 580                        Ramp+
         |           |            | I- 880                        Ramp+
         |           |            | Sp Railroad                       +
         |           |            | I- 580                            +
         |           |            | I- 680                        Ramp
 name    | t         |  -0.284859 | I- 880                        Ramp+
         |           |            | I- 580                        Ramp+
         |           |            | I- 680                        Ramp+
         |           |            | I- 580                            +
         |           |            | State Hwy 13                  Ramp
(2 rows)
</screen>

   Notez que deux lignes sont affichées pour la même colonne, une correspondant
   à la hiérarchie d'héritage complète commençant à la table
   <literal>road</literal> (<literal>inherited</literal>=<literal>t</literal>),
   et une autre incluant seulement la table <literal>road</literal> elle-même
   (<literal>inherited</literal>=<literal>f</literal>).

  </para>

  <para>
   Le nombre d'informations stockées dans
   <structname>pg_statistic</structname> par <command>ANALYZE</command>,
   en particulier le nombre maximum
   d'éléments dans les tableaux <structfield>most_common_vals</structfield> et
   <structfield>histogram_bounds</structfield> pour chaque colonne, peut être initialisé
   sur une base colonne-par-colonne en utilisant la commande <command>ALTER
   TABLE SET STATISTICS</command> ou globalement en initialisant la variable de
   configuration <xref linkend="guc-default-statistics-target"/>. La limite par
   défaut est actuellement de cent entrées. Augmenter la limite pourrait
   permettre des estimations plus précises du planificateur, en particulier
   pour les colonnes ayant des distributions de données irrégulières, au prix
   d'un plus grand espace consommé dans <structname>pg_statistic</structname> et
   en un temps plus long pour calculer les estimations. En revanche, une limite
   plus basse pourrait être suffisante pour les colonnes à distributions de
   données simples.
  </para>

  <para>
   Le <xref linkend="planner-stats-details"/> donne plus de détails sur
   l'utilisation des statistiques par le planificateur.
  </para>

 </sect1>

 <sect1 id="explicit-joins">
  <title>Contrôler le planificateur avec des clauses <literal>JOIN</literal>
   explicites</title>

  <indexterm zone="explicit-joins">
   <primary>jointure</primary>
   <secondary>contrôlant l'ordre</secondary>
  </indexterm>

  <para>
   Il est possible de contrôler le planificateur de requêtes à un certain
   point en utilisant une syntaxe <literal>JOIN</literal> explicite. Pour voir en
   quoi ceci est important, nous avons besoin de quelques connaissances.
  </para>

  <para>
   Dans une simple requête de jointure, telle que&nbsp;:
<programlisting>SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;</programlisting>
   le planificateur est libre de joindre les tables données dans n'importe
   quel ordre. Par exemple, il pourrait générer un plan de requête qui joint A à
   B en utilisant la condition <literal>WHERE</literal> <literal>a.id = b.id</literal>, puis
   joint C à cette nouvelle table jointe en utilisant l'autre condition
   <literal>WHERE</literal>. Ou il pourrait joindre B à C, puis A au résultat de cette
   jointure précédente. Ou il pourrait joindre A à C puis les joindre avec B
   mais cela pourrait ne pas être efficace car le produit cartésien complet de A
   et C devra être formé alors qu'il n'y a pas de condition applicable dans la
   clause <literal>WHERE</literal> pour permettre une optimisation de la jointure
   (toutes les jointures dans l'exécuteur <productname>PostgreSQL</productname>
   arrivent entre deux tables en entrées donc il est nécessaire de construire le
   résultat de l'une ou de l'autre de ces façons). Le point important est que
   ces différentes possibilités de jointures donnent des résultats
   sémantiquement équivalents mais pourraient avoir des coûts d'exécution
   grandement différents. Du coup, le planificateur va toutes les explorer pour
   trouver le plan de requête le plus efficace.
  </para>

  <para>
   Quand une requête implique seulement deux ou trois tables, il y a peu
   d'ordres de jointures à préparer. Mais le nombre d'ordres de jointures
   possibles grandit de façon exponentielle au fur et à mesure que le nombre de
   tables augmente. Au-delà de dix tables en entrée, il n'est plus possible de
   faire une recherche exhaustive de toutes les possibilités et même la
   planification de six ou sept tables pourrait prendre beaucoup de temps.
   Quand il y a trop de tables en entrée, le planificateur
   <productname>PostgreSQL</productname> basculera d'une recherche exhaustive à
   une recherche <firstterm>génétique</firstterm> probabiliste via un nombre
   limité de possibilités (la limite de bascule est initialisée par le paramètre
   en exécution <xref linkend="guc-geqo-threshold"/>). La recherche génétique prend
   moins de temps mais elle ne trouvera pas nécessairement le meilleur plan
   possible.
  </para>

  <para>
   Quand la requête implique des jointures externes, le planificateur est moins
   libre qu'il ne l'est lors de jointures internes. Par exemple, considérez&nbsp;:
<programlisting>SELECT * FROM a LEFT JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);</programlisting>
   Bien que les restrictions de cette requête semblent superficiellement
   similaires à l'exemple précédent, les sémantiques sont différentes car une
   ligne doit être émise pour chaque ligne de A qui n'a pas de ligne
   correspondante dans la jointure entre B et C. Du coup, le planificateur n'a
   pas de choix dans l'ordre de la jointure ici&nbsp;: il doit joindre B à C
   puis joindre A à ce résultat. Du coup, cette requête prend moins de temps à
   planifier que la requête précédente. Dans d'autres cas, le planificateur
   pourrait être capable de déterminer que plus d'un ordre de jointure est
   sûr. Par exemple, étant donné&nbsp;:
<programlisting>
SELECT * FROM a LEFT JOIN b ON (a.bid = b.id) LEFT JOIN c ON (a.cid = c.id);
</programlisting>
   il est valide de joindre A à soit B soit C en premier. Actuellement, seul un
   <literal>FULL JOIN</literal> contraint complètement l'ordre de jointure. La
   plupart des cas pratiques impliquant un <literal>LEFT JOIN</literal> ou un
   <literal>RIGHT JOIN</literal> peuvent être arrangés jusqu'à un certain degré.
  </para>

  <para>
   La syntaxe de jointure interne explicite (<literal>INNER
   JOIN</literal>, <literal>CROSS JOIN</literal> ou <literal>JOIN</literal>) est sémantiquement
   identique à lister les relations en entrées du <literal>FROM</literal>, donc il
   ne contraint pas l'ordre de la jointure.
  </para>

  <para>
   Même si la plupart des types de <literal>JOIN</literal> ne contraignent pas
   complètement l'ordre de jointure, il est possible d'instruire le planificateur
   de requête de <productname>PostgreSQL</productname> pour qu'il traite toutes
   les clauses <literal>JOIN</literal> de façon à contraindre quand même l'ordre
   de jointure.
   Par exemple, ces trois requêtes sont logiquement équivalentes&nbsp;:
<programlisting>SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;
SELECT * FROM a CROSS JOIN b CROSS JOIN c WHERE a.id = b.id AND b.ref = c.id;
SELECT * FROM a JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);</programlisting>
   Mais si nous disons au planificateur d'honorer l'ordre des
   <literal>JOIN</literal>, la deuxième et la troisième prendront moins de temps à
   planifier que la première. Cet effet n'est pas inquiétant pour seulement
   trois tables mais cela pourrait bien nous aider avec un nombre important
   de tables.
  </para>

  <para>
   Pour forcer le planificateur à suivre l'ordre de jointure demandé par les
   <literal>JOIN</literal> explicites, initialisez le paramètre en exécution
   <xref linkend="guc-join-collapse-limit"/> à 1 (d'autres valeurs possibles
   sont discutées plus bas).
  </para>

  <para>
   Vous n'avez pas besoin de restreindre l'ordre de jointure pour diminuer le 
   temps de recherche car il est bien d'utiliser les opérateurs <literal>JOIN</literal>
   dans les éléments d'une liste <literal>FROM</literal>. Par exemple,
   considérez&nbsp;:
<programlisting>SELECT * FROM a CROSS JOIN b, c, d, e WHERE ...;</programlisting>
   Avec <varname>join_collapse_limit</varname> = 1, ceci force le planificateur à
   joindre A à B avant de les joindre aux autres tables mais sans restreindre
   ses choix. Dans cet exemple, le nombre d'ordres de jointures possibles
   est réduit par un facteur de cinq.
  </para>

  <para>
   Restreindre la recherche du planificateur de cette façon est une technique
   utile pour réduire les temps de planification et pour diriger le
   planificateur vers un bon plan de requêtes. Si le planificateur choisit un
   mauvais ordre de jointure par défaut, vous pouvez le forcer à choisir un
   meilleur ordre via la syntaxe <literal>JOIN</literal> &mdash; en supposant que vous
   connaissiez un meilleur ordre. Une expérimentation est recommandée.
  </para>

  <para>
   Un problème très proche et affectant le temps de planification est le
   regroupement de sous-requêtes dans leurs requêtes parents. Par exemple,
   considérez&nbsp;:
<programlisting>SELECT *
FROM x, y,
    (SELECT * FROM a, b, c WHERE quelquechose) AS ss
WHERE quelquechosedautre;</programlisting>
   Cette requête pourrait survenir suite à l'utilisation d'une vue contenant une
   jointure&nbsp;; la règle <literal>SELECT</literal> de la vue sera insérée à la
   place de la référence de la vue, demande une requête plutôt identique à celle
   ci-dessus. Normalement, le planificateur essaiera de regrouper la
   sous-requête avec son parent, donnant&nbsp;:
<programlisting>SELECT * FROM x, y, a, b, c WHERE quelquechose AND quelquechosedautre;</programlisting>
   Ceci résulte habituellement en un meilleur plan que de planifier séparément
   la sous-requête (par exemple, les conditions <literal>WHERE</literal> externes
   pourraient être telles que joindre X à A élimine en premier lieu un bon
   nombre de lignes de A, évitant ainsi le besoin de former la sortie complète
   de la sous-requête). Mais en même temps, nous avons accru le temps de
   planification&nbsp;; ici, nous avons une problème de jointure à cinq tables
   remplaçant un problème de deux jointures séparées à trois tables. À cause de
   l'augmentation exponentielle du nombre de possibilités, ceci fait une grande
   différence. Le planificateur essaie d'éviter de se retrouver coincé dans des
   problèmes de recherche de grosses jointures en ne regroupant pas une
   sous-requête sur plus de <varname>from_collapse_limit</varname>
   éléments sont la résultante de la requête parent. Vous
   pouvez comparer le temps de planification avec la qualité du plan en
   ajustant ce paramètre en exécution.
  </para>

  <para>
   <xref linkend="guc-from-collapse-limit"/> et <xref
   linkend="guc-join-collapse-limit"/> sont
   nommés de façon similaire parce qu'ils font pratiquement la même chose&nbsp;:
   l'un d'eux contrôle le moment où le planificateur <quote>aplatira</quote> les
   sous-requêtes et l'autre contrôle s'il y a aplatissement des jointures
   explicites. Typiquement, vous initialiserez 
   <varname>join_collapse_limit</varname> comme <varname>from_collapse_limit</varname> (de
   façon à ce que les jointures explicites et les sous-requêtes agissent de la
   même façon) ou vous initialiserez <varname>join_collapse_limit</varname> à 1 (si
   vous voulez contrôler l'ordre de jointure des jointures explicites). Mais
   vous pourriez les initialiser différemment si vous tentez de configurer
   finement la relation entre le temps de planification et le temps
   d'exécution.
  </para>
 </sect1>

 <sect1 id="populate">
  <title>Remplir une base de données</title>

  <para>
   Vous pourriez avoir besoin d'insérer un grand nombre de données pour
   remplir une base de données au tout début. Cette section contient quelques
   suggestions pour réaliser cela de la façon la plus efficace.
  </para>

  <sect2 id="disable-autocommit">
   <title>Désactivez la validation automatique (autocommit)</title>

   <indexterm>
    <primary>autocommit</primary>
    <secondary>gros chargement de données</secondary>
   </indexterm>

   <para>
    Lors d'<command>INSERT</command> multiples, désactivez la validation automatique et faites
    une seule validation à la
    fin (en SQL, ceci signifie de lancer <command>BEGIN</command> au début et
   <command>COMMIT</command> à la fin. Quelques bibliothèques client pourraient
   le faire derrière votre dos auquel cas vous devez vous assurer que la
   bibliothèque le fait quand vous le voulez). Si vous permettez à chaque
   insertion d'être validée séparément, <productname>PostgreSQL</productname>
   fait un gros travail pour chaque ligne ajoutée. Un bénéfice supplémentaire de
   réaliser toutes les insertions dans une seule transaction est que si l'insertion
   d'une ligne échoue alors les lignes insérées jusqu'à maintenant seront
   annulées. Vous ne serez donc pas bloqué avec des données partiellement
   chargées.
   </para>
  </sect2>

  <sect2 id="populate-copy-from">
   <title>Utilisez <command>COPY</command></title>

   <para>
    Utilisez <xref linkend="sql-copy"/> pour charger
    toutes les lignes en une seule commande, plutôt que d'utiliser une série
    de commandes <command>INSERT</command>. La commande <command>COPY</command>
    est optimisée pour charger un grand nombre de lignes&nbsp;; elle est moins
    flexible que <command>INSERT</command> mais introduit significativement moins
    de surcharge lors du chargement de grosses quantités de données. Comme
    <command>COPY</command> est une seule commande, il n'y a pas besoin de
    désactiver la validation automatique (autocommit) si vous utilisez cette
    méthode pour remplir une table.
   </para>

   <para>
    Si vous ne pouvez pas utiliser <command>COPY</command>, utiliser <xref
    linkend="sql-prepare"/> pourrait vous aider à
    créer une instruction préparée <command>INSERT</command>, puis utilisez
    <command>EXECUTE</command> autant de fois que nécessaire. Ceci évite
    certaines surcharges lors d'une analyse et d'une planification répétées
    de commandes <command>INSERT</command>. Différentes interfaces fournissent
    cette fonctionnalité de plusieurs façons&nbsp;; recherchez
    <quote>instructions préparées</quote> dans la documentation de l'interface.
   </para>

   <para>
    Notez que charger un grand nombre de lignes en utilisant
    <command>COPY</command> est pratiquement toujours plus rapide que d'utiliser
    <command>INSERT</command>, même si <command>PREPARE ... INSERT</command> est utilisé lorsque
    de nombreuses insertions sont groupées en une seule transaction.
   </para>

   <para>
    <command>COPY</command> est plus rapide quand il est utilisé dans la même
    transaction que la commande <command>CREATE TABLE</command> ou
    <command>TRUNCATE</command> précédente. Dans ce cas, les journaux de
    transactions ne sont pas impactés car, en cas d'erreur, les fichiers
    contenant les données nouvellement chargées seront supprimés de toute
    façon. Néanmoins, cette considération ne s'applique que quand
    <xref linkend="guc-wal-level"/> vaut <literal>minimal</literal>, car toutes les
    commandes doivent écrire dans les journaux de transaction dans ce cas.
   </para>

  </sect2>

  <sect2 id="populate-rm-indexes">
   <title>Supprimez les index</title>

   <para>
    Si vous chargez une table tout juste créée, la méthode la plus rapide est de
    créer la table, de charger en lot les données de cette table en utilisant
    <command>COPY</command>, puis de créer tous les index nécessaires pour la
    table. Créer un index sur des données déjà existantes est plus rapide que de
    mettre à jour de façon incrémentale à chaque ligne ajoutée.
   </para>

   <para>
    Si vous ajoutez beaucoup de données à une table existante, il pourrait être
    avantageux de supprimer les index, de charger la table, puis de recréer les
    index.
    Bien sûr, les performances de la base de données pour les autres utilisateurs
    pourraient souffrir tout le temps où les index seront manquant. Vous devez aussi
    y penser à deux fois avant de supprimer des index uniques car la vérification
    d'erreur apportée par la contrainte unique sera perdue tout le temps où
    l'index est manquant.
   </para>
  </sect2>

  <sect2 id="populate-rm-fkeys">
   <title>Suppression des contraintes de clés étrangères</title>

   <para>
    Comme avec les index, une contrainte de clé étrangère peut être vérifiée
    <quote>en gros volume</quote> plus efficacement que ligne par ligne.
    Donc, il pourrait être utile de supprimer les contraintes de clés
    étrangères, de charger les données et de créer de nouveau les contraintes.
    De nouveau, il y a un compromis entre la vitesse de chargement des données
    et la perte de la vérification des erreurs lorsque la contrainte manque.
   </para>

   <para>
    What's more, when you load data into a table with existing foreign key
    constraints, each new row requires an entry in the server's list of
    pending trigger events (since it is the firing of a trigger that checks
    the row's foreign key constraint).  Loading many millions of rows can
    cause the trigger event queue to overflow available memory, leading to
    intolerable swapping or even outright failure of the command.  Therefore
    it may be <emphasis>necessary</emphasis>, not just desirable, to drop and re-apply
    foreign keys when loading large amounts of data.  If temporarily removing
    the constraint isn't acceptable, the only other recourse may be to split
    up the load operation into smaller transactions.
   </para>
  </sect2>

  <sect2 id="populate-work-mem">
   <title>Augmentez <varname>maintenance_work_mem</varname></title>

   <para>
    Augmentez temporairement la variable <xref linkend="guc-maintenance-work-mem"/>
    lors du chargement de grosses quantités de données peut amener une
    amélioration des performances. Ceci aidera à l'accélération des commandes
    <command>CREATE INDEX</command> et <command>ALTER TABLE ADD FOREIGN KEY</command>. Cela
    ne changera pas grand chose pour la commande <command>COPY</command>. Donc, ce
    conseil est seulement utile quand vous utilisez une des deux ou les deux
    techniques ci-dessus.
   </para>
  </sect2>

  <sect2 id="populate-checkpoint-segments">
   <title>Augmentez <varname>checkpoint_segments</varname></title>

   <para>
    Augmenter temporairement la variable de configuration <xref
    linkend="guc-checkpoint-segments"/> peut aussi aider à un chargement
    rapide de grosses quantités de données. Ceci est dû au fait que charger
    une grosse quantité de données dans <productname>PostgreSQL</productname>
    causera la venue trop fréquente de points de vérification (la
    fréquence de ces points de vérification est spécifiée par la variable de
    configuration <varname>checkpoint_timeout</varname>). Quand survient un
    point de vérification, toutes les pages modifiées sont écrites sur le
    disque. En augmentant <varname>checkpoint_segments</varname> temporairement
    lors du chargement des données, le nombre de points de vérification requis
    peut être diminué.
   </para>
  </sect2>

  <sect2 id="populate-pitr">
   <title>Désactiver l'archivage des journaux de transactions et la
     réplication en flux</title>

   <para>
    Lors du chargement de grosse quantité de données dans une instance qui
    utilise l'archivage des journaux de transactions ou la réplication en
    flux, il pourrait être plus rapide de prendre une nouvelle sauvegarde de
    base après que le chargement ait terminé, plutôt que de traiter une grosse
    quantité de données incrémentales dans les journaux de transactions. Pour
    empêcher un accroissement de la journalisation des transactions lors du
    chargement, vous
    pouvez désactiver l'archivage et la réplication en flux lors du chargement
    en configurant <xref linkend="guc-wal-level"/> à <literal>minimal</literal>,
    <xref linkend="guc-archive-mode"/> à <literal>off</literal> et
    <xref linkend="guc-max-wal-senders"/> à zéro). Mais notez que le changement
    de ces paramètres requiert un redémarrage du serveur.
   </para>

   <para>
    En dehors d'éviter le temps de traitement des données des journaux de
    transactions par l'archiveur ou l'émetteur des journaux de transactions,
    le faire rendrait certaines commandes plus rapides parce qu'elles sont
    conçues pour ne pas écrire du tout dans les journaux de transactions si
    <varname>wal_level</varname> vaut <literal>minimal</literal>. (Elles
    peuvent garantir la sûreté des données de façon moins coûteuse en exécutant
    un <function>fsync</function> à la fin plutôt qu'en écrivant les journaux
    de transactions&nbsp;:
    <itemizedlist>
     <listitem>
      <para>
       <command>CREATE TABLE AS SELECT</command>
      </para>
     </listitem>
     <listitem>
      <para>
       <command>CREATE INDEX</command> (et les variantes telles que
       <command>ALTER TABLE ADD PRIMARY KEY</command>)
      </para>
     </listitem>
     <listitem>
      <para>
       <command>ALTER TABLE SET TABLESPACE</command>
      </para>
     </listitem>
     <listitem>
      <para>
       <command>CLUSTER</command>
      </para>
     </listitem>
     <listitem>
      <para>
       <command>COPY FROM</command>, quand la table cible vient d'être créée
       ou vidée auparavant dans la transaction
      </para>
     </listitem>
    </itemizedlist>
   </para>
  </sect2>

  <sect2 id="populate-analyze">
   <title>Lancez <command>ANALYZE</command> après</title>

   <para>
     Quand vous avez changé significativement la distribution des données à
     l'intérieur d'une table, lancer <xref linkend="sql-analyze"/> est fortement
     recommandée. Ceci inclut le
     chargement de grosses quantités de données dans la table. Lancer
     <command>ANALYZE</command> (ou <command>VACUUM ANALYZE</command>) vous
     assure que le planificateur dispose de statistiques à jour sur la table.
     Sans statistiques ou avec des statistiques obsolètes, le planificateur
     pourrait prendre de mauvaises décisions lors de la planification de la
     requête, amenant des performances pauvres sur toutes les tables sans
     statistiques ou avec des statistiques inexactes. Notez que si le démon
     autovacuum est désactivée, il pourrait exécuter <command>ANALYZE</command>
     automatiquement&nbsp;; voir <xref linkend="vacuum-for-statistics"/> et
     <xref linkend="autovacuum"/> pour plus d'informations.
   </para>
  </sect2>

  <sect2 id="populate-pg-dump">
   <title>Quelques notes sur <application>pg_dump</application></title>

   <para>
    Les scripts de sauvegarde générés par <application>pg_dump</application> appliquent
    automatiquement plusieurs des indications ci-dessus, mais pas toutes. Pour
    recharger une sauvegarde <application>pg_dump</application> aussi rapidement que
    possible, vous avez besoin de faire quelques étapes supplémentaires
    manuellement (notez que ces points s'appliquent lors de la
    <emphasis>restauration</emphasis> d'une sauvegarde, et non pas lors de sa
    <emphasis>création</emphasis>. Les mêmes points s'appliquent soit lors de
    la restauration d'une sauvegarde texte avec <application>psql</application> soit lors
    de l'utilisation
    de <application>pg_restore</application> pour charger un fichier de sauvegarde
    <application>pg_dump</application>).
   </para>

   <para>
    Par défaut, <application>pg_dump</application> utilise
    <command>COPY</command> et, lorsqu'il génère une sauvegarde complexe,
    schéma et données, il est préférable de charger les données avant de créer
    les index et les clés étrangères. Donc, dans ce cas, plusieurs lignes de
    conduite sont gérées automatiquement. Ce qui vous reste à faire est
    de&nbsp;:
    <itemizedlist>
     <listitem>
      <para>
       Configurez des valeurs appropriées (c'est-à-dire plus importante que la
       normale) pour <varname>maintenance_work_mem</varname> et
       <varname>checkpoint_segments</varname>.
      </para>
     </listitem>
     <listitem>
      <para>
       Si vous utilisez l'archivage des journaux de transactions ou la
       réplication en flux, considérez leur désactivation lors de la
       restauration. Pour faire cela, configurez
       <varname>archive_mode</varname> à <literal>off</literal>, <varname>wal_level</varname> à
       <literal>minimal</literal> et <varname>max_wal_senders</varname> à zéro
       avant de charger le script de sauvegarde. Après coup, remettez les
       anciennes valeurs et effectuez une nouvelle sauvegarde de base.
      </para>
     </listitem>
     <listitem>
      <para>
       Demandez-vous si la sauvegarde complète doit être restaurée dans une
       seule transaction. Pour cela, passez l'option <option>-1</option> ou
       <option>--single-transaction</option> à
       <application>psql</application> pi <application>pg_restore</application>.
       Lors de l'utilisation de ce mode, même les erreurs les plus petites
       annuleront la restauration complète, peut-être en annulant des heures de
       traitement. Suivant à quel point les données sont en relation, il peut
       être préférable de faire un nettoyage manuel. Les commandes
       <command>COPY</command> s'exécuteront plus rapidement si vous utilisez une
       transaction simple et que vous avez désactivé l'archivage des journaux de
       transaction.
      </para>
     </listitem>
     <listitem>
      <para>
       Si plusieurs processeurs sont disponibles sur le serveur, pensez à
       utiliser l'option <option>--jobs</option> de
       <application>pg_restore</application>. Cela permet la parallélisation
       du chargement des données et de la création des index.
      </para>
     </listitem>
     <listitem>
      <para>
       Exécutez <command>ANALYZE</command> après coup.
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <para>
    Une sauvegarde des données seules utilise toujours <command>COPY</command> mais
    elle ne supprime ni ne recrée les index et elle ne touche généralement pas
    les clés étrangères.

     <footnote>
      <para>
       Vous pouvez obtenir l'effet de désactivation des clés étrangères en
       utilisant l'option <option>--disable-triggers</option> &mdash; mais réalisez
       que cela élimine, plutôt que repousse, la validation des clés étrangères
       et qu'il est du coup possible d'insérer des données mauvaises si vous
       l'utilisez.
      </para>
     </footnote>

    Donc, lorsque vous chargez une sauvegarde ne contenant que les données,
    c'est à vous de supprimer et recréer les index et clés étrangères si vous
    souhaitez utiliser ces techniques. Il est toujours utile d'augmenter
    <varname>checkpoint_segments</varname> lors du chargement des données
    mais ne vous embêtez pas à augmenter
    <varname>maintenance_work_mem</varname>&nbsp;; en fait, vous le ferez lors
    d'une nouvelle création manuelle des index et des clés étrangères. Et
    n'oubliez pas <command>ANALYZE</command> une fois que vous avez terminé&nbsp;;
    voir <xref linkend="vacuum-for-statistics"/> et <xref linkend="autovacuum"/>
    pour plus d'informations.
   </para>
  </sect2>
 </sect1>

  <sect1 id="non-durability">
   <title>Configuration avec une perte acceptée</title>

   <indexterm zone="non-durability">
    <primary>perte acceptée</primary>
   </indexterm>

   <para>
    La durabilité est une fonctionnalité des serveurs de bases de données
    permettant de garantir l'enregistrement des transactions validées même si
    le serveur s'arrête brutalement, par exemple en cas de coupure électrique.
    Néanmoins, la durabilité ajoute une surcharge significative. Si votre
    base de données n'a pas besoin de cette ganratie,
    <productname>PostgreSQL</productname> peut être configuré pour fonctionner
    bien plus rapidement. Voici des modifications de configuration que vous
    pouvez faire pour améliorer les performances dans ce cas. Sauf indication
    contraire, la durabilité des transactions est garantie dans le cas d'un
    crash du serveur de bases de données&nbsp;; seul un arrêt brutal du
    système d'exploitation crée un risque de perte de données ou de
    corruption quand ses paramètres sont utilisés.

    <itemizedlist>
     <listitem>
      <para>
       Placer le répertoire des données dans un système de fichiers en
       mémoire (par exemple un disque <acronym>RAM</acronym>). Ceci élimine
       toutes les entrées/sorties disque de la base de données. Cela limite
       aussi la quantité de mémoire disponible (et peut-être aussi du swap).
      </para>
     </listitem>

     <listitem>
      <para>
       Désactiver <xref linkend="guc-fsync"/>&nbsp;; il n'est pas nécessaire
       d'écrire les données sur disque.
      </para>
     </listitem>

     <listitem>
      <para>
       Désactiver <xref linkend="guc-full-page-writes"/>&nbsp;; il n'est pas
       nécessaire de se prémunir contre les écritures de pages partielles.
      </para>
     </listitem>

     <listitem>
      <para>
       Augmenter <xref linkend="guc-checkpoint-segments"/> et <xref
       linkend="guc-checkpoint-timeout"/>&nbsp;; cela réduit les fréquences
       des CHECKPOINT mais augmente l'espace disque nécessaire dans
       <filename>pg_xlog</filename>.
      </para>
     </listitem>

     <listitem>
      <para>
       Désactiver <xref linkend="guc-synchronous-commit"/>&nbsp;; il n'est
       pas forcément nécessaire d'écrire les journaux de transactions
       (<acronym>WAL</acronym>) à chaque validation de transactions. Ce
       paramètre engendre un risque de perte de transactions (mais pas de
       corruption de données) dans le cas d'un crash de la
       <emphasis>base de données</emphasis> seule.
      </para>
     </listitem>
    </itemizedlist>
   </para>
  </sect1>
</chapter>
